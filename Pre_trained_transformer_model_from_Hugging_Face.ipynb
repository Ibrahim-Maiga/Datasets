{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQaasmzBeA6kOQ7SwBfL7a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibrahim-Maiga/Datasets/blob/main/Pre_trained_transformer_model_from_Hugging_Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the data\n",
        "url = 'https://raw.githubusercontent.com/Ibrahim-Maiga/Datasets/main/stock_data.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Clean the text data\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "data['Sentiment'] = data['Sentiment'].replace(-1, 0)\n",
        "data['cleaned_text'] = data['Text'].apply(clean_text)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'], data['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipe = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
        "\n",
        "# Classify the sentiment of the test data\n",
        "results = pipe(X_test.to_list())\n",
        "\n",
        "# Convert results to binary labels\n",
        "preds = [1 if result['label'] == 'LABEL_1' else 0 for result in results]\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "print(f'Pipeline Accuracy: {accuracy}')\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
        "\n",
        "# Tokenize the data\n",
        "train_encodings = tokenizer(X_train.to_list(), truncation=True, padding=True, max_length=50)\n",
        "test_encodings = tokenizer(X_test.to_list(), truncation=True, padding=True, max_length=50)\n",
        "\n",
        "# Convert data to torch tensors\n",
        "train_labels = torch.tensor(y_train.values, dtype=torch.long)\n",
        "test_labels = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_encodings['input_ids']), torch.tensor(train_encodings['attention_mask']), train_labels)\n",
        "test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_encodings['input_ids']), torch.tensor(test_encodings['attention_mask']), test_labels)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Set the model to training mode\n",
        "model.train()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "total_steps = len(train_loader) * 3  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(3):  # Training for 3 epochs\n",
        "    for batch in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Evaluate the model\n",
        "preds = []\n",
        "true_labels = []\n",
        "eval_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        logits = outputs.logits\n",
        "        loss = outputs.loss\n",
        "        eval_loss += loss.item()\n",
        "        preds.extend(torch.argmax(logits, dim=1).tolist())\n",
        "        true_labels.extend(labels.tolist())\n",
        "\n",
        "# Calculate accuracy and average loss\n",
        "accuracy = accuracy_score(true_labels, preds)\n",
        "avg_loss = eval_loss / len(test_loader)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Average Loss: {avg_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25yz5wopR2TN",
        "outputId": "00eeb664-4275-4c78-ce27-af9cc9f7ffa6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline Accuracy: 0.3684210526315789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "100%|██████████| 290/290 [20:28<00:00,  4.23s/it]\n",
            "100%|██████████| 290/290 [20:19<00:00,  4.20s/it]\n",
            "100%|██████████| 290/290 [20:17<00:00,  4.20s/it]\n",
            "100%|██████████| 73/73 [01:26<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8153580672993961\n",
            "Average Loss: 0.456393631124129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "# Calculate accuracy and average loss\n",
        "accuracy = accuracy_score(true_labels, preds)\n",
        "avg_loss = eval_loss / len(test_loader)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(true_labels, preds)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Average Loss: {avg_loss}')\n",
        "print(f'Recall: {recall}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtViWt8-RRdk",
        "outputId": "37fd748b-f4eb-4e61-de61-06b861431f97"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8153580672993961\n",
            "Average Loss: 0.456393631124129\n",
            "Recall: 0.8565573770491803\n"
          ]
        }
      ]
    }
  ]
}